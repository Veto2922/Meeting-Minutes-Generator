{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching transcript from YouTube video: https://www.youtube.com/watch?v=9hE5-98ZeCg\n",
      "\n",
      "=== Transcript Preview ===\n",
      "\n",
      "Okay, this is a quick demo of multimodal live streaming in Gemini 2.0. and we are casting a tab into AI Studio. Um, can you see my screen? Yes, I see your screen. It's showing a document with the title Demo. It also contains bullet points and a Google Meet window with a person in the video. Is there anything in particular you would like to talk about on the screen? Yeah, can you start the demo by just reading the text I highlighted? Sure, I can do that. The text you highlighted reads, The Multimodal Live API lets you build real-time multimodal applications powered by Gemini 2.0 Flash. It features tool use like Google Search and code execution, function calling, and more. Would you like me to read the following lines too? No, can you actually just tell me what this word means though? I can do that. Multimodal refers to the ability to process and understand different types of data like text, images, and audio all together. Does that help? Yeah, um, I need to demo the interruptions featur\n",
      "\n",
      "=== Meeting Minutes ===\n",
      "\n",
      "**Meeting Minutes**\n",
      "\n",
      "**1. Meeting Title:** Demo of Multimodal Live Streaming in Gemini 2.0\n",
      "\n",
      "**2. Date & Time:** [Not mentioned]\n",
      "\n",
      "**3. Attendees:**\n",
      "*   Presenter\n",
      "*   AI Studio Assistant\n",
      "\n",
      "**4. Agenda Items:**\n",
      "*   Introduction to Multimodal Live Streaming in Gemini 2.0.\n",
      "*   Demonstration of text reading and information extraction from the screen.\n",
      "*   Clarification of technical terms (e.g., \"multimodal\").\n",
      "*   Demonstration of the interruptions handling feature.\n",
      "*   Demonstration of the memory/summarization feature.\n",
      "*   Concluding remarks and call to action.\n",
      "\n",
      "**5. Discussion Summary:**\n",
      "The meeting commenced with a quick demo of multimodal live streaming in Gemini 2.0, casting a tab into AI Studio. The AI Studio Assistant confirmed visibility of the presenter's screen, identifying a document with bullet points and a Google Meet window.\n",
      "\n",
      "Key demonstrations included:\n",
      "*   **Text Reading:** The presenter asked the AI Assistant to read highlighted text from the screen. The AI successfully read: \"The Multimodal Live API lets you build real-time multimodal applications powered by Gemini 2.0 Flash. It features tool use like Google Search and code execution, function calling, and more.\"\n",
      "*   **Definition:** The AI Assistant was asked to define \"multimodal.\" It accurately defined it as \"the ability to process and understand different types of data like text, images, and audio all together.\"\n",
      "*   **Interruptions Feature:** The presenter requested a \"boring once upon a time story\" to demonstrate the interruption feature. The presenter interrupted the AI Assistant mid-sentence, which the AI acknowledged, confirming the feature's functionality.\n",
      "*   **Memory Feature:** To demonstrate memory, the AI Assistant was asked to summarize everything seen or heard so far. The AI provided an accurate summary, recalling the discussion about the Multimodal Live API, the definition of multimodal, and the interrupted story.\n",
      "*   **Conclusion:** The AI Assistant concluded the demo by reading the ending card which displayed: \"Start building with Gemini 2.0 at aistudio.google.com.\"\n",
      "\n",
      "**6. Decisions Made:**\n",
      "[None]\n",
      "\n",
      "**7. Action Items:**\n",
      "[None]\n",
      "\n",
      "**8. Next Meeting:**\n",
      "[Not mentioned]\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load API key\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "client = genai.Client(api_key=api_key)\n",
    "\n",
    "# === Choose Your Input ===\n",
    "# Option 1: Local file\n",
    "local_file_path = r\"..\\data\\denver_extract.mp3\"  # Replace with your path\n",
    "use_youtube = True  # Set to True if using YouTube instead\n",
    "\n",
    "# Option 2: YouTube video URL\n",
    "youtube_url = \"https://www.youtube.com/watch?v=9hE5-98ZeCg\"  # Replace with your URL\n",
    "\n",
    "# === Step 1: Transcribe the content ===\n",
    "if use_youtube:\n",
    "    print(f\"Fetching transcript from YouTube video: {youtube_url}\")\n",
    "    transcription_response = client.models.generate_content(\n",
    "        model=\"gemini-2.5-flash\",\n",
    "        contents=types.Content(\n",
    "            parts=[\n",
    "                types.Part(\n",
    "                    file_data=types.FileData(file_uri=youtube_url)\n",
    "                ),\n",
    "                types.Part(text=\"Transcribe the audio from this video.\")\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "else:\n",
    "    print(f\"Uploading local file: {local_file_path}\")\n",
    "    uploaded_file = client.files.upload(file=local_file_path)\n",
    "    print(f\"Uploaded file ID: {uploaded_file.name}\")\n",
    "    \n",
    "    transcription_response = client.models.generate_content(\n",
    "        model=\"gemini-2.5-flash\",\n",
    "        contents=[\"Generate a transcript of the speech.\", uploaded_file]\n",
    "    )\n",
    "\n",
    "# === Step 2: Extract transcript text ===\n",
    "transcript = transcription_response.text\n",
    "print(\"\\n=== Transcript Preview ===\\n\")\n",
    "print(transcript[:1000])  # Print only first 1000 characters\n",
    "\n",
    "# === Step 3: Generate Meeting Minutes ===\n",
    "system_prompt = \"\"\"\n",
    "You are a professional meeting assistant. You will be given a transcript of a meeting from a video or audio recording.\n",
    "\n",
    "Your task is to generate clear and concise **Meeting Minutes** in a structured format that includes the following sections:\n",
    "\n",
    "1. **Meeting Title** (if mentioned)\n",
    "2. **Date & Time**\n",
    "3. **Attendees**\n",
    "4. **Agenda Items**\n",
    "5. **Discussion Summary**\n",
    "6. **Decisions Made**\n",
    "7. **Action Items**\n",
    "8. **Next Meeting**\n",
    "\n",
    "ðŸ“Œ Make the minutes formal and easy to read.\n",
    "ðŸ“Œ If some information is missing, write: [Not mentioned].\n",
    "\n",
    "Now here is the transcript:\n",
    "\"\"\"\n",
    "\n",
    "minutes_response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    config=types.GenerateContentConfig(\n",
    "        system_instruction=system_prompt.strip()\n",
    "    ),\n",
    "    contents=transcript\n",
    ")\n",
    "\n",
    "print(\"\\n=== Meeting Minutes ===\\n\")\n",
    "print(minutes_response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai \n",
    "from google.genai import types\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "client = genai.Client(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "system_prompt = \"\"\"\n",
    "\n",
    "You are a professional meeting assistant. You will be given a transcript of a meeting from a video or audio recording.\n",
    "\n",
    "Your task is to generate clear and concise **Meeting Minutes** in a structured format that includes the following sections:\n",
    "\n",
    "1. **Meeting Title** (if mentioned)\n",
    "2. **Date & Time**\n",
    "3. **Attendees**\n",
    "4. **Agenda Items**\n",
    "5. **Discussion Summary** â€“ summarize the main points of discussion.\n",
    "6. **Decisions Made** â€“ list key decisions taken during the meeting.\n",
    "7. **Action Items** â€“ include what needs to be done, by whom, and by when (if mentioned).\n",
    "8. **Next Meeting** â€“ mention the proposed date/time if available.\n",
    "\n",
    "ðŸ“Œ Make the minutes formal and easy to read.\n",
    "ðŸ“Œ If some information is missing (e.g., attendees or date), leave a placeholder like [Not mentioned].\n",
    "\n",
    "Now here is the transcript:\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "transcript = \"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Meeting Minutes - Denver City Council Meeting**\n",
      "\n",
      "**1. Meeting Title:** Denver City Council Meeting\n",
      "\n",
      "**2. Date & Time:** Monday, October 9th, 2017 (Meeting commenced at 6:00 PM for the Halloween parade announcement, actual council meeting time not specified beyond the date)\n",
      "\n",
      "**3. Attendees:**\n",
      "*   Councilman Clark\n",
      "*   Councilman Espinoza\n",
      "*   Councilman Gilmore\n",
      "*   Councilman Kashmann\n",
      "*   Councilman Kniech\n",
      "*   Councilman Lopez\n",
      "*   Councilman New\n",
      "*   Councilman Ortega\n",
      "*   Councilman Sussman\n",
      "*   Mr. President\n",
      "*   (Absent: Black, Flynn)\n",
      "*   *Quorum present with 11 members.*\n",
      "\n",
      "**4. Agenda Items:**\n",
      "*   Pledge of Allegiance\n",
      "*   Roll Call\n",
      "*   Approval of Minutes (October 2nd)\n",
      "*   Council Announcements\n",
      "*   Presentations\n",
      "*   Communications\n",
      "*   Proclamation 1127: Indigenous Peoples' Day in the City and County of Denver\n",
      "\n",
      "**5. Discussion Summary:**\n",
      "The meeting opened with the Pledge of Allegiance. Following roll call, the minutes from October 2nd were approved. Councilman Clark announced the first-ever Broadway Halloween parade in District 7, scheduled for Saturday, October 21st, at 6:00 PM, moving from 3rd to Alameda. No presentations or communications were received.\n",
      "\n",
      "The main focus of the meeting was Proclamation 1127, observing the annual Indigenous Peoples' Day in the City and County of Denver. Councilman Lopez read the proclamation, highlighting:\n",
      "*   The indigenous peoples have lived and flourished on the Americas since time immemorial, with Denver built on ancestral homelands of numerous tribes (Southern Ute, Ute Mountain, Arapahoe, Cheyenne, etc.).\n",
      "*   Colorado encompasses ancestral homelands of 48 tribes, and Denver is home to descendants of approximately 100 tribal nations.\n",
      "*   Denver officially designated the second Monday of October as Indigenous Peoples' Day in 2016.\n",
      "*   The Council recognizes the vast contributions of indigenous peoples to community, knowledge, science, philosophy, art, and culture.\n",
      "*   The indigenous community, especially youth, have drawn attention to these contributions through initiatives like \"Confluence Week.\"\n",
      "*   The proclamation celebrates and honors cultural and foundational contributions, promoting education about indigenous history and contemporary impact.\n",
      "\n",
      "Councilman Lopez emphasized that Indigenous Peoples' Day is a celebration of pride and inclusivity, not contempt or disrespect for other cultures, echoing a quote from Cesar Chavez. He noted Denver's leadership in celebrating this day, having been featured in Time Magazine and Newsweek. He stressed that the day is \"a day on,\" for addressing critical issues like poverty and lack of services affecting indigenous communities. Councilwoman Ortega expressed her support, highlighting the preservation of indigenous language and culture, and her experience with the Commission on Indian Affairs. Councilwoman Kniech thanked the artist for the \"Confluence Week\" logo, connecting the imagery of water and land to the importance of indigenous communities in defending public lands and environmental protection, expressing solidarity with their resistance. The President concluded by reiterating that Indigenous Peoples' Day represents inclusivity and respect for those whose history has been historically silenced.\n",
      "\n",
      "**6. Decisions Made:**\n",
      "*   Minutes of October 2nd approved.\n",
      "*   Proclamation 1127 (Indigenous Peoples' Day) was moved, seconded, and adopted.\n",
      "\n",
      "**7. Action Items:**\n",
      "*   The Clerk of the City and County of Denver shall attest and affix the seal to Proclamation 1127.\n",
      "*   A copy of Proclamation 1127 to be transmitted to the Denver American Indian Commission, the City and County of Denver School District Number 1, and the Colorado Commission on Indian Affairs.\n",
      "*   Councilman Clark invited all to the Broadway Halloween Parade on October 21st at 6:00 PM.\n",
      "\n",
      "**8. Next Meeting:**\n",
      "[Not mentioned]\n"
     ]
    }
   ],
   "source": [
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    config=types.GenerateContentConfig(\n",
    "        system_instruction=system_prompt),\n",
    "    contents=transcript\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
